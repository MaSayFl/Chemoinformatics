{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c74271",
   "metadata": {},
   "source": [
    "## Deepchem practical tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0e9cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5baabcc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import deepchem as dc\n",
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85731273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20945617",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78fe3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a27c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0] [0.0] [0.0] 0\n",
      "[1.0, 1.0] [0.0] [0.0] 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dataset = dc.data.NumpyDataset(np.ones((2,2)))\n",
    "for x, y, w, id in dataset.itersamples():\n",
    "    print(x.tolist(), y.tolist(), w.tolist(), id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7bbfbb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.98061288, 0.51613009, 0.64889066, 0.20825363, 0.32777987,\n",
       "         0.61200768, 0.26747545, 0.8585619 , 0.06894629, 0.91007398],\n",
       "        [0.50289433, 0.7670384 , 0.62159224, 0.81093639, 0.79424752,\n",
       "         0.46826205, 0.69337994, 0.50866602, 0.97735135, 0.69990091],\n",
       "        [0.6140219 , 0.37558648, 0.51959826, 0.44720134, 0.08134524,\n",
       "         0.21439663, 0.08637916, 0.89782651, 0.42676526, 0.87740057],\n",
       "        [0.10296489, 0.14044087, 0.91670406, 0.38471363, 0.05389896,\n",
       "         0.50735557, 0.41653522, 0.64925473, 0.05373749, 0.420119  ],\n",
       "        [0.07105486, 0.67035387, 0.80185969, 0.44948472, 0.67762173,\n",
       "         0.95557751, 0.46046668, 0.36845699, 0.26362487, 0.54592717],\n",
       "        [0.89588203, 0.46052511, 0.01911249, 0.25006961, 0.6460712 ,\n",
       "         0.0469692 , 0.40661947, 0.61423298, 0.19020875, 0.86404968]]),\n",
       " array([[0.91793046],\n",
       "        [0.65706537],\n",
       "        [0.6120886 ],\n",
       "        [0.14507993],\n",
       "        [0.97935215],\n",
       "        [0.65168843]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.random((6, 10))\n",
    "y = np.random.random((6, 1))\n",
    "dataset = dc.data.NumpyDataset(x,y)\n",
    "dataset.X, dataset.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11f7fb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<NumpyDataset X.shape: (4, 10), y.shape: (4, 1), w.shape: (4, 1), ids: [5 2 0 3], task_names: [0]>,\n",
       " <NumpyDataset X.shape: (2, 10), y.shape: (2, 1), w.shape: (2, 1), ids: [4 1], task_names: [0]>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = dc.splits.RandomSplitter()\n",
    "train_dataset, test_dataset = splitter.train_test_split(dataset)\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7cc6f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<NumpyDataset X.shape: (4, 10), y.shape: (4, 1), w.shape: (4, 1), ids: [3 2 4 0], task_names: [0]>,\n",
       " <NumpyDataset X.shape: (1, 10), y.shape: (1, 1), w.shape: (1, 1), ids: [5], task_names: [0]>,\n",
       " <NumpyDataset X.shape: (1, 10), y.shape: (1, 1), w.shape: (1, 1), ids: [1], task_names: [0]>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset)\n",
    "train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5937b343",
   "metadata": {},
   "source": [
    "For predicting toxicity, we will use the Tox21 toxicity dataset from MoleculeNet and we will use DeepChem to load the required dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9c18d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9972562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = tox21_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28c1fd97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CC(O)(P(=O)(O)O)P(=O)(O)O',\n",
       "       'CC(C)(C)OOC(C)(C)CCC(C)(C)OOC(C)(C)C',\n",
       "       'OC[C@H](O)[C@@H](O)[C@H](O)CO', ...,\n",
       "       'O=C1OC(OC(=O)c2cccnc2Nc2cccc(C(F)(F)F)c2)c2ccccc21',\n",
       "       'CC(=O)C1(C)CC2=C(CCCC2(C)C)CC1C',\n",
       "       'CC(C)CCC[C@@H](C)[C@H]1CC(=O)C2=C3CC[C@H]4C[C@@H](O)CC[C@]4(C)[C@H]3CC[C@@]21C'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a43183a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NR-AR', 'NR-AR-LBD', 'NR-AhR', 'NR-Aromatase', 'NR-ER', 'NR-ER-LBD', 'NR-PPAR-gamma', 'SR-ARE', 'SR-ATAD5', 'SR-HSE', 'SR-MMP', 'SR-p53']\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(tox21_tasks)\n",
    "print(len(tox21_tasks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "896ae4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<DiskDataset X.shape: (6264, 1024), y.shape: (6264, 12), w.shape: (6264, 12), task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>, <DiskDataset X.shape: (783, 1024), y.shape: (783, 12), w.shape: (783, 12), ids: ['N#C[C@@H]1CC(F)(F)CN1C(=O)CNC1CC2CCC(C1)N2c1ncccn1'\n",
      " 'CN(C)C(=O)NC1(c2ccccc2)CCN(CCC[C@@]2(c3ccc(Cl)c(Cl)c3)CCCN(C(=O)c3ccccc3)C2)CC1'\n",
      " 'CSc1nnc(C(C)(C)C)c(=O)n1N' ...\n",
      " 'O=C(O[C@H]1CN2CCC1CC2)N1CCc2ccccc2[C@@H]1c1ccccc1'\n",
      " 'C#C[C@]1(O)CC[C@H]2[C@@H]3CCC4=CC(=O)CC[C@@H]4[C@H]3C(=C)C[C@@]21CC'\n",
      " 'NC(=O)C(c1ccccc1)(c1ccccc1)[C@@H]1CCN(CCc2ccc3c(c2)CCO3)C1'], task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>, <DiskDataset X.shape: (784, 1024), y.shape: (784, 12), w.shape: (784, 12), ids: ['CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O.CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)O.c1ccc(CNCCNCc2ccccc2)cc1'\n",
      " 'CC(C)(c1ccc(Oc2ccc3c(c2)C(=O)OC3=O)cc1)c1ccc(Oc2ccc3c(c2)C(=O)OC3=O)cc1'\n",
      " 'Cc1cc(C(C)(C)C)c(O)c(C)c1Cn1c(=O)n(Cc2c(C)cc(C(C)(C)C)c(O)c2C)c(=O)n(Cc2c(C)cc(C(C)(C)C)c(O)c2C)c1=O'\n",
      " ... 'CN[C@@H]1C[C@@H](c2ccc(Cl)c(Cl)c2)c2ccccc21'\n",
      " 'Cl/C=C\\\\C[N+]12CN3CN(CN(C3)C1)C2'\n",
      " 'NC(=O)c1ccc[n+]([C@@H]2O[C@H](COP(=O)([O-])OP(=O)(O)OC[C@H]3O[C@@H](n4cnc5c(N)ncnc54)[C@H](O)[C@@H]3O)[C@@H](O)[C@H]2O)c1'], task_names: ['NR-AR' 'NR-AR-LBD' 'NR-AhR' ... 'SR-HSE' 'SR-MMP' 'SR-p53']>)\n"
     ]
    }
   ],
   "source": [
    "print(tox21_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca09c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<deepchem.trans.transformers.BalancingTransformer at 0x7f290547aa10>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e50bd5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6264, 1024) (783, 1024)\n",
      "(6264, 12) (783, 12)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.X.shape, valid_dataset.X.shape)\n",
    "print(np.shape(train_dataset.y), np.shape(valid_dataset.y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1888738b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6264, 12) 63647 11521\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.w.shape,\n",
    "      np.count_nonzero(train_dataset.w),\n",
    "      np.count_nonzero(train_dataset.w == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a111d",
   "metadata": {},
   "source": [
    "Теперь попробуем создать и обучить модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85cf82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-27 22:48:01.010526: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2021-10-27 22:48:01.010626: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (mariia-G3-3590): /proc/driver/nvidia/version does not exist\n",
      "2021-10-27 22:48:01.011948: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-10-27 22:48:01.603726: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "model = dc.models.MultitaskClassifier(n_tasks=12, n_features=1024, layer_sizes=[1000]) #задаем алгоритм\n",
    "model.fit(train_dataset, nb_epoch=10) #обучаем модель\n",
    "#определяем метрики, по которым будем оценивать качество модели\n",
    "metric = dc.metrics.Metric(dc.metrics.roc_auc_score, np.mean)\n",
    "train_scores = model.evaluate(train_dataset, [metric], transformers)\n",
    "test_scores = model.evaluate(test_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7352b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC for train dataset: {'mean-roc_auc_score': 0.9589079279769371}\n",
      "AUC-ROC for test dataset: {'mean-roc_auc_score': 0.6835421842194602}\n"
     ]
    }
   ],
   "source": [
    "print(f'AUC-ROC for train dataset: {train_scores}')\n",
    "print(f'AUC-ROC for test dataset: {test_scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a9ae5",
   "metadata": {},
   "source": [
    "Тут видно, что модель переобучаеся и отрабатывает не очень хорошо на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64761032",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0541b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed12f292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10784532546997071"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)\n",
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b242b5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function KerasModel._compute_model at 0x7f28a5aee5f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "{'pearson_r2_score': 0.9205461853034781}\n",
      "{'pearson_r2_score': 0.6820242335644608}\n"
     ]
    }
   ],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "print(model.evaluate(train_dataset, [metric], transformers))\n",
    "print(model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e132b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = ['COC(C)(C)CCCC(C)CC=CC(C)=CC(=O)OC(C)C',\n",
    "'CCOC(=O)CC',\n",
    "'CSc1nc(NC(C)C)nc(NC(C)C)n1',\n",
    "'CC(C#C)N(C)C(=O)Nc1ccc(Cl)cc1',\n",
    "'Cc1cc2ccccc2cc1C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a2acde8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.550318  ],\n",
       "       [ 1.4608353 ],\n",
       "       [ 0.44491947],\n",
       "       [-0.5343154 ],\n",
       "       [-1.209742  ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "mols = [Chem.MolFromSmiles(s) for s in smiles]\n",
    "featurizer = dc.feat.ConvMolFeaturizer()\n",
    "x = featurizer.featurize(mols)\n",
    "predicted_solubility = model.predict_on_batch(x)\n",
    "predicted_solubility"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
